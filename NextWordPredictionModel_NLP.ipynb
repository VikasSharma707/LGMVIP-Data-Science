{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NextWordPredictionModel_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOCdmqiV0EAdeLR+ZFzCEvn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VikasSharma707/LGMVIP-Data-Science/blob/main/NextWordPredictionModel_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pGLqPx79V4M"
      },
      "source": [
        "# **LGM-VIP Data Science Internship Programme 2021**\n",
        "## **ADVANCED LEVEL TASK**\n",
        "# **Name: Next Word Prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORnSHKJw9wLM"
      },
      "source": [
        "**libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_f1l5bFiCUb"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWwvN1u6het3"
      },
      "source": [
        "path = 'nextword.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4xXYuB39_5Q"
      },
      "source": [
        "**Preprocessing the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "hmQfbHgoh95r",
        "outputId": "c9151ae1-b80d-4ebd-a066-a88031f8ebec"
      },
      "source": [
        "file = open(\"nextword.txt\", \"r\", encoding = \"utf8\")\n",
        "\n",
        "# store file in list\n",
        "lines = []\n",
        "for i in file:\n",
        "    lines.append(i)\n",
        "\n",
        "# Convert list to string\n",
        "data = \"\"\n",
        "for i in lines:\n",
        "  data = ' '. join(lines) \n",
        "\n",
        "#replace unnecessary stuff with space\n",
        "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '').replace('“','').replace('”','')  #new line, carriage return, unicode character --> replace by space\n",
        "\n",
        "#remove unnecessary spaces \n",
        "data = data.split()\n",
        "data = ' '.join(data)\n",
        "data[:200]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Project Gutenberg's The Adventures of Sherlock Holmes, by Arthur Conan Doyle This eBook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever. You may copy it, give i\""
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88jkFUyrj2Wf",
        "outputId": "d33f3ae8-7ae2-4c7f-c355-bd8dcd743ee7"
      },
      "source": [
        "print(len(data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "573660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGYuzQrevrcN",
        "outputId": "eb80449e-db28-4df5-950f-856df8f8047d"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=len(data), oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts([data])\n",
        "\n",
        "# saving the tokenizer for predict function\n",
        "pickle.dump(tokenizer, open('token.pkl', 'wb'))\n",
        "\n",
        "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
        "sequence_data[:15]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[143, 4681, 2, 987, 6, 126, 34, 47, 557, 2165, 2166, 28, 988, 15, 23]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFJfUsp9vxrE",
        "outputId": "6e3971ca-ad6f-4f7b-83b5-443d9e68ec15"
      },
      "source": [
        "print(len(sequence_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "108958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dfVa1sIwZA3",
        "outputId": "b7cd0823-79c2-4489-ccac-0c788499e833"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyKC8Zwvwdi3",
        "outputId": "1b9b1fa4-ea40-4445-cb97-93c01e131af4"
      },
      "source": [
        "sequences = []\n",
        "\n",
        "for i in range(3, len(sequence_data)):\n",
        "    words = sequence_data[i-3:i+1]\n",
        "    sequences.append(words)\n",
        "    \n",
        "print(\"The Length of sequences are: \", len(sequences))\n",
        "sequences = np.array(sequences)\n",
        "sequences[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Length of sequences are:  108955\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 143, 4681,    2,  987],\n",
              "       [4681,    2,  987,    6],\n",
              "       [   2,  987,    6,  126],\n",
              "       [ 987,    6,  126,   34],\n",
              "       [   6,  126,   34,   47],\n",
              "       [ 126,   34,   47,  557],\n",
              "       [  34,   47,  557, 2165],\n",
              "       [  47,  557, 2165, 2166],\n",
              "       [ 557, 2165, 2166,   28],\n",
              "       [2165, 2166,   28,  988]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy9bo5eMwgXI"
      },
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in sequences:\n",
        "    X.append(i[0:3])\n",
        "    y.append(i[3])\n",
        "    \n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb6Ds8BRwkAX",
        "outputId": "df40a8d2-6521-40ca-fe36-252aae349b51"
      },
      "source": [
        "print(\"Data: \", X[:10])\n",
        "print(\"Response: \", y[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data:  [[ 143 4681    2]\n",
            " [4681    2  987]\n",
            " [   2  987    6]\n",
            " [ 987    6  126]\n",
            " [   6  126   34]\n",
            " [ 126   34   47]\n",
            " [  34   47  557]\n",
            " [  47  557 2165]\n",
            " [ 557 2165 2166]\n",
            " [2165 2166   28]]\n",
            "Response:  [ 987    6  126   34   47  557 2165 2166   28  988]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMariKIEwmZ4",
        "outputId": "8ceab507-b1d3-4397-f92a-38570099f461"
      },
      "source": [
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "y[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thAlyt-uA14e"
      },
      "source": [
        "**MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMHtk0L-wpNr"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 10, input_length=3))\n",
        "model.add(LSTM(1000, return_sequences=True))\n",
        "model.add(LSTM(1000))\n",
        "model.add(Dense(1000, activation=\"relu\"))\n",
        "model.add(Dense(vocab_size, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ienbmn6UwsB2",
        "outputId": "1c1583bb-cbb8-43c2-bfc1-930a0567461f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 3, 10)             86250     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 3, 1000)           4044000   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 1000)              8004000   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1000)              1001000   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8625)              8633625   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,768,875\n",
            "Trainable params: 21,768,875\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1kj3mYjwuaX",
        "outputId": "90e36170-7a87-4f5b-84ef-cc9838acff9e"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"next_words.h5\", monitor='loss', verbose=1, save_best_only=True)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001))\n",
        "model.fit(X, y, epochs=20, batch_size=64, callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1702/1703 [============================>.] - ETA: 0s - loss: 6.3896\n",
            "Epoch 00001: loss improved from inf to 6.38954, saving model to next_words.h5\n",
            "1703/1703 [==============================] - 65s 34ms/step - loss: 6.3895\n",
            "Epoch 2/20\n",
            "1703/1703 [==============================] - ETA: 0s - loss: 5.8027\n",
            "Epoch 00002: loss improved from 6.38954 to 5.80273, saving model to next_words.h5\n",
            "1703/1703 [==============================] - 59s 35ms/step - loss: 5.8027\n",
            "Epoch 3/20\n",
            "1702/1703 [============================>.] - ETA: 0s - loss: 5.4754\n",
            "Epoch 00003: loss improved from 5.80273 to 5.47527, saving model to next_words.h5\n",
            "1703/1703 [==============================] - 59s 35ms/step - loss: 5.4753\n",
            "Epoch 4/20\n",
            "1703/1703 [==============================] - ETA: 0s - loss: 5.2078\n",
            "Epoch 00004: loss improved from 5.47527 to 5.20780, saving model to next_words.h5\n",
            "1703/1703 [==============================] - 59s 35ms/step - loss: 5.2078\n",
            "Epoch 5/20\n",
            "1703/1703 [==============================] - ETA: 0s - loss: 4.9788\n",
            "Epoch 00005: loss improved from 5.20780 to 4.97880, saving model to next_words.h5\n",
            "1703/1703 [==============================] - 59s 35ms/step - loss: 4.9788\n",
            "Epoch 6/20\n",
            "1703/1703 [==============================] - ETA: 0s - loss: 4.7528\n",
            "Epoch 00006: loss improved from 4.97880 to 4.75281, saving model to next_words.h5\n",
            "1703/1703 [==============================] - 59s 35ms/step - loss: 4.7528\n",
            "Epoch 7/20\n",
            "1703/1703 [==============================] - ETA: 0s - loss: 4.5191\n",
            "Epoch 00007: loss improved from 4.75281 to 4.51912, saving model to next_words.h5\n",
            "1703/1703 [==============================] - 59s 34ms/step - loss: 4.5191\n",
            "Epoch 8/20\n",
            "1702/1703 [============================>.] - ETA: 0s - loss: 4.2770\n",
            "Epoch 00008: loss improved from 4.51912 to 4.27710, saving model to next_words.h5\n",
            "1703/1703 [==============================] - 59s 35ms/step - loss: 4.2771\n",
            "Epoch 9/20\n",
            "1702/1703 [============================>.] - ETA: 0s - loss: 4.0209\n",
            "Epoch 00009: loss improved from 4.27710 to 4.02094, saving model to next_words.h5\n",
            "1703/1703 [==============================] - 59s 35ms/step - loss: 4.0209\n",
            "Epoch 10/20\n",
            "1702/1703 [============================>.] - ETA: 0s - loss: 3.7618\n",
            "Epoch 00010: loss improved from 4.02094 to 3.76171, saving model to next_words.h5\n",
            "1703/1703 [==============================] - 59s 35ms/step - loss: 3.7617\n",
            "Epoch 11/20\n",
            "1702/1703 [============================>.] - ETA: 0s - loss: 3.5008\n",
            "Epoch 00011: loss improved from 3.76171 to 3.50096, saving model to next_words.h5\n",
            "1703/1703 [==============================] - 59s 35ms/step - loss: 3.5010\n",
            "Epoch 12/20\n",
            "1703/1703 [==============================] - ETA: 0s - loss: 3.2483\n",
            "Epoch 00012: loss improved from 3.50096 to 3.24829, saving model to next_words.h5\n",
            "1703/1703 [==============================] - 59s 35ms/step - loss: 3.2483\n",
            "Epoch 13/20\n",
            "1703/1703 [==============================] - ETA: 0s - loss: 3.0053\n",
            "Epoch 00013: loss improved from 3.24829 to 3.00526, saving model to next_words.h5\n",
            "1703/1703 [==============================] - 59s 35ms/step - loss: 3.0053\n",
            "Epoch 14/20\n",
            "1703/1703 [==============================] - ETA: 0s - loss: 2.7701\n",
            "Epoch 00014: loss improved from 3.00526 to 2.77009, saving model to next_words.h5\n",
            "1703/1703 [==============================] - 59s 34ms/step - loss: 2.7701\n",
            "Epoch 15/20\n",
            "1703/1703 [==============================] - ETA: 0s - loss: 2.5378\n",
            "Epoch 00015: loss improved from 2.77009 to 2.53783, saving model to next_words.h5\n",
            "1703/1703 [==============================] - 59s 35ms/step - loss: 2.5378\n",
            "Epoch 16/20\n",
            "1703/1703 [==============================] - ETA: 0s - loss: 2.3103\n",
            "Epoch 00016: loss improved from 2.53783 to 2.31028, saving model to next_words.h5\n",
            "1703/1703 [==============================] - 59s 35ms/step - loss: 2.3103\n",
            "Epoch 17/20\n",
            "1702/1703 [============================>.] - ETA: 0s - loss: 2.0950\n",
            "Epoch 00017: loss improved from 2.31028 to 2.09497, saving model to next_words.h5\n",
            "1703/1703 [==============================] - 59s 35ms/step - loss: 2.0950\n",
            "Epoch 18/20\n",
            "1703/1703 [==============================] - ETA: 0s - loss: 1.8804\n",
            "Epoch 00018: loss improved from 2.09497 to 1.88036, saving model to next_words.h5\n",
            "1703/1703 [==============================] - 59s 35ms/step - loss: 1.8804\n",
            "Epoch 19/20\n",
            "1703/1703 [==============================] - ETA: 0s - loss: 1.6827\n",
            "Epoch 00019: loss improved from 1.88036 to 1.68270, saving model to next_words.h5\n",
            "1703/1703 [==============================] - 59s 35ms/step - loss: 1.6827\n",
            "Epoch 20/20\n",
            "1702/1703 [============================>.] - ETA: 0s - loss: 1.5137\n",
            "Epoch 00020: loss improved from 1.68270 to 1.51375, saving model to next_words.h5\n",
            "1703/1703 [==============================] - 59s 35ms/step - loss: 1.5138\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f357a9af250>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9Vmhd3AA_qZ"
      },
      "source": [
        "**Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foY9rxorw14p"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model = load_model('next_words.h5')\n",
        "tokenizer = pickle.load(open('token.pkl', 'rb'))\n",
        "\n",
        "def Predict_Next_Words(model, tokenizer, text):\n",
        "\n",
        "  sequence = tokenizer.texts_to_sequences([text])\n",
        "  sequence = np.array(sequence)\n",
        "  preds = np.argmax(model.predict(sequence))\n",
        "  predicted_word = \"\"\n",
        "  \n",
        "  for key, value in tokenizer.word_index.items():\n",
        "      if value == preds:\n",
        "          predicted_word = key\n",
        "          break\n",
        "  \n",
        "  print(predicted_word)\n",
        "  return predicted_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldAEiNHOw7oT",
        "outputId": "9a6a3439-4fe4-4c59-eba6-350182fdb08d"
      },
      "source": [
        "while(True):\n",
        "  text = input(\"Enter your line: \")\n",
        "  \n",
        "  if text == \"0\":\n",
        "      print(\"Execution completed.....\")\n",
        "      break\n",
        "  \n",
        "  else:\n",
        "      try:\n",
        "          text = text.split(\" \")\n",
        "          text = text[-3:]\n",
        "          print(text)\n",
        "        \n",
        "          Predict_Next_Words(model, tokenizer, text)\n",
        "          \n",
        "      except Exception as e:\n",
        "        print(\"Error occurred: \",e)\n",
        "        continue"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Adventures']\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 3), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
            "of\n",
            "['Arthur', 'Conan']\n",
            "i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrupAfkje4f_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}